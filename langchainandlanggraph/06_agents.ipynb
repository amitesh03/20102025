{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Developing Basic Agents in LangChain - Interactive Notebook\n\nThis notebook provides hands-on exercises to accompany the agents lesson:\n- Define tools with input schemas and docstrings\n- Build ReAct-style agents\n- Use OpenAI tool/function-calling agents\n- Add memory and streaming to agents\n- Handle parsing errors and retries\n- Practice exercises for tool design and agent behavior\n\nEnsure your `.env` has necessary keys (e.g., OPENAI_API_KEY)."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 0) Setup and Imports"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import os\nfrom typing import Optional, Dict, Any\nfrom dotenv import load_dotenv\nload_dotenv()\n\n# LLMs, prompts, memory\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.memory import ConversationBufferMemory\n\n# Tools\nfrom langchain_core.tools import tool\n\n# Agent construction (ReAct / tool-calling)\nreact_available = True\ntools_agent_available = True\ntry:\n    from langchain.agents import create_react_agent, create_openai_tools_agent, AgentExecutor\nexcept Exception as e:\n    print(\"Agent constructors not directly available from langchain.agents in this version.\")\n    print(\"Error:\", e)\n    react_available = False\n    tools_agent_available = False\n\n# Streaming callbacks\nfrom langchain_core.callbacks import StreamingStdOutCallbackHandler\n\nprint(\"Setup complete.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1) Define Tools\nTools should be pure, safe, with clear docstrings and compact outputs."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from math import isfinite\n\n@tool\ndef calculator(expression: str) -> str:\n    \"\"\"Evaluate a basic arithmetic expression like '2 + 3 * 4'.\"\"\"\n    try:\n        # WARNING: eval is unsafe for untrusted input. Use a proper expression parser in production.\n        result = eval(expression, {\"__builtins__\": {}}, {})\n        if isinstance(result, (int, float)) and isfinite(result):\n            return str(result)\n        return \"calc-error: non-finite result\"\n    except Exception as e:\n        return f\"calc-error: {e}\"\n\n@tool\ndef search_local_docs(query: str, corpus: Optional[str] = None) -> str:\n    \"\"\"Fake search over a small in-memory corpus. Provide a short answer from local notes.\"\"\"\n    notes = (corpus or \"LangChain supports prompts, chains, agents, and memory for LLM apps.\")\n    if query.lower() in notes.lower():\n        return f\"Found mention of '{query}': ... {notes[:120]} ...\"\n    return \"No relevant snippets found.\"\n\ntools = [calculator, search_local_docs]\nprint(\"Tools registered:\", [t.name for t in tools])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2) Build a ReAct Agent\nReAct alternates between reasoning (Thought), tool use (Action), and observation (Observation)."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "llm = None\ntry:\n    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\nexcept Exception as e:\n    print(\"ChatOpenAI unavailable (check OPENAI_API_KEY):\", e)\n\nreact_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a helpful assistant. Use tools when helpful. Think step-by-step.\"),\n    (\"human\", \"{input}\")\n])\n\nif react_available and llm is not None:\n    try:\n        agent = create_react_agent(llm=llm, tools=tools, prompt=react_prompt)\n        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n        result = agent_executor.invoke({\"input\": \"What is (12+8)/5? Then check if 'agents' appear in our local notes.\"})\n        print(\"Agent output:\\n\", result.get(\"output\"))\n    except Exception as e:\n        print(\"ReAct agent execution failed:\", e)\nelse:\n    print(\"ReAct path unavailable in this environment/version.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Handle parsing and tool errors gracefully\nUse `handle_parsing_errors=True` in `AgentExecutor` to allow the agent to recover from minor format issues."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "if react_available and llm is not None:\n    try:\n        agent = create_react_agent(llm=llm, tools=tools, prompt=react_prompt)\n        safe_exec = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n        bad = safe_exec.invoke({\"input\": \"Compute 3 * (4 + bad)\"})\n        print(\"Safe output:\\n\", bad.get(\"output\"))\n    except Exception as e:\n        print(\"Safe executor encountered an error:\", e)\nelse:\n    print(\"Skipping safe executor: ReAct not available.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3) OpenAI Tool-Calling Agent\nLeverage function/tool-calling from OpenAI chat models via LangChain utilities when available."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "if tools_agent_available and llm is not None:\n    try:\n        tool_prompt = ChatPromptTemplate.from_messages([\n            (\"system\", \"You are a precise assistant. Use tools when necessary.\"),\n            (\"human\", \"{input}\")\n        ])\n        tool_agent = create_openai_tools_agent(llm, tools, tool_prompt)\n        tool_exec = AgentExecutor(agent=tool_agent, tools=tools, verbose=True)\n        out = tool_exec.invoke({\"input\": \"Use the calculator to evaluate (7*9)-8 and tell me the result.\"})\n        print(\"Tool-calling output:\\n\", out.get(\"output\"))\n    except Exception as e:\n        print(\"OpenAI tools agent execution failed:\", e)\nelse:\n    print(\"OpenAI tools agent path not available.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4) Adding Memory to Agents\nUse a conversational prompt and buffer memory to preserve recent context for coherent follow-ups."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "if react_available and llm is not None:\n    memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"input\")\n    mem_prompt = ChatPromptTemplate.from_messages([\n        (\"system\", \"You are helpful. Use the chat history as needed.\"),\n        (\"placeholder\", \"{chat_history}\"),\n        (\"human\", \"{input}\")\n    ])\n    try:\n        mem_agent = create_react_agent(llm=llm, tools=tools, prompt=mem_prompt)\n        mem_exec = AgentExecutor(agent=mem_agent, tools=tools, verbose=True, memory=memory)\n        print(mem_exec.invoke({\"input\": \"Remember that I like short answers.\"})[\"output\"])\n        print(mem_exec.invoke({\"input\": \"What did I say about answer style?\"})[\"output\"])\n    except Exception as e:\n        print(\"Memory-enabled agent failed:\", e)\nelse:\n    print(\"Skipping memory integration: ReAct or LLM unavailable.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5) Streaming Agent Responses\nStream tokens for better UX and observability during longer responses or multi-step tool use."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "try:\n    stream_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\nexcept Exception as e:\n    stream_llm = None\n    print(\"Streaming LLM unavailable:\", e)\n\nif react_available and stream_llm is not None:\n    try:\n        stream_agent = create_react_agent(llm=stream_llm, tools=tools, prompt=react_prompt)\n        stream_exec = AgentExecutor(agent=stream_agent, tools=tools, verbose=True)\n        _ = stream_exec.invoke({\"input\": \"Show your steps and compute 17*19 using the calculator.\"})\n    except Exception as e:\n        print(\"Streaming agent failed:\", e)\nelse:\n    print(\"Streaming path not available.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6) Exercises\nA) Calculator + Units Agent\n- Implement a `unit_convert(value: float, from_unit: str, to_unit: str)` tool for km<->miles.\n- Build an agent that decides between `calculator` or `unit_convert`.\n- Test: \"What is 150 miles in km plus 12?\".\n\nB) Local Notes QA Agent\n- Add a `load_notes(topic: str)` tool that reads a snippet from `./notes/*.txt`.\n- Combine with `search_local_docs` to answer: \"Find any mention of 'vector memory' and summarize in one sentence.\".\n\nC) Robustness\n- Use `handle_parsing_errors=True` in `AgentExecutor`.\n- Simulate a tool error and show a graceful fallback message.\n\nD) Memory-Aware Agent\n- Integrate `ConversationBufferMemory` and verify follow-up consistency.\n\nE) Observability\n- Log timing and tool inputs/outputs; print a minimal trace after each run."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercise Scaffold: Unit Conversion Tool and Agent"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from dataclasses import dataclass\n\n@tool\ndef unit_convert(value: float, from_unit: str, to_unit: str) -> str:\n    \"\"\"Convert simple units, currently supports miles<->km (case-insensitive).\"\"\"\n    conv = {\n        (\"miles\", \"km\"): 1.60934,\n        (\"km\", \"miles\"): 1/1.60934,\n    }\n    try:\n        k = (from_unit.strip().lower(), to_unit.strip().lower())\n        if k not in conv:\n            return \"convert-error: unsupported units\"\n        return str(value * conv[k])\n    except Exception as e:\n        return f\"convert-error: {e}\"\n\nexercise_tools = [calculator, unit_convert]\nprint(\"Exercise tools:\", [t.name for t in exercise_tools])\n\nif react_available and llm is not None:\n    try:\n        ex_prompt = ChatPromptTemplate.from_messages([\n            (\"system\", \"You are a careful assistant. Prefer calculator for arithmetic and unit_convert for unit changes.\"),\n            (\"human\", \"{input}\")\n        ])\n        ex_agent = create_react_agent(llm=llm, tools=exercise_tools, prompt=ex_prompt)\n        ex_exec = AgentExecutor(agent=ex_agent, tools=exercise_tools, verbose=True, handle_parsing_errors=True)\n        # Try: 150 miles to km, then +12\n        out = ex_exec.invoke({\"input\": \"Convert 150 miles to km and add 12 to the result.\"})\n        print(\"Exercise agent output:\\n\", out.get(\"output\"))\n    except Exception as e:\n        print(\"Exercise agent failed:\", e)\nelse:\n    print(\"Skipping exercise agent construction.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7) Observability: Minimal Tracing for Tool Calls\nCreate a wrapper to log calls and durations of each tool invocation."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import time\nfrom functools import wraps\n\ndef log_tool(fn):\n    @wraps(fn)\n    def wrapper(*args, **kwargs):\n        start = time.time()\n        try:\n            result = fn(*args, **kwargs)\n            return result\n        finally:\n            dur = (time.time() - start) * 1000\n            print(f\"[tool] {fn.__name__} took {dur:.1f} ms\")\n    return wrapper\n\n# Wrap raw callables if needed (LangChain tool decorators already generate Tool objects)\nwrapped_calc = log_tool(calculator.func)\nprint(\"2+2 via wrapped calc:\", wrapped_calc(\"2+2\"))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\nYou built tools and agents (ReAct and OpenAI tool-calling), added memory and streaming, and handled parsing errors. Complete the exercises to deepen your understanding and adapt these patterns for your applications."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}